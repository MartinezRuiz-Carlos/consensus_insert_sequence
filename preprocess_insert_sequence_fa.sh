#!/bin/bash

# Script to pre-process the insert fasta file generated by Savana and divide it into multiple fasta files per SV ID
INPUT_INSERTS=$1
OUTPUT=$2
mkdir -p ${OUTPUT}
# Get fasta sequences into a single line
awk '/^>/ {printf("\n%s\n",$0);next; } { printf("%s",$0);}  END {printf("\n");}' < ${INPUT_INSERTS} > ${OUTPUT}/tmp_oneline.fasta
# Get the sequences to align from the savana output (ID[0-9]+-INS.+)
INSERT_IDS=($(grep '^>' ${INPUT_INSERTS} | cut -d '-' -f 1 | sort -u | sed 's/^>//g' | tr '\n' ' '))

# Split the fasta by ID
for THIS_ID in ${INSERT_IDS[@]}; do
    grep ${THIS_ID}- -A1 ${OUTPUT}/tmp_oneline.fasta > ${OUTPUT}/${THIS_ID}.fasta
done

THIS NEEDS A BIG REVAMP, MAKE MORE EFFICIENT, USE SEQKIT GREP ONCE THE CONDE ENVS ARE BACK TO NORMAL (OR DOCKERIZE):https://bioinf.shenwei.me/seqkit/usage/#grep
# Ensure run has finished successfuly and remove tmp fasta
if [ $? -eq 0 ]; then
    echo "DONE"
    rm ${OUTPUT}/tmp_oneline.fasta
fi